{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Variational Hamiltonian Ansatz on the Hubbard model\n",
    "\n",
    "The Hubbard model is a simplification of correlated electrons. Despite its simplistic structure, the Hubbard model is able to capture some interesting physics, such as the transition of a solid from a conducting to insulating state and some superconducting effects (though I don't yet understand any of this). \n",
    "\n",
    "In this notebook, we'll briefly describe the Hubbard model and then try to use the VHA to solve it. \n",
    "\n",
    "$\\newcommand{\\ket}[1]{\\lvert #1 \\rangle}$\n",
    "$\\newcommand{\\bra}[1]{\\langle #1 \\rvert}$\n",
    "$\\newcommand{\\braket}[1]{\\langle #1 \\rangle}$\n",
    "\n",
    "**Update 1**: I started by defining my own classes/functions for creation/annihilation operators, the Jordan-Wigner transform, the square lattice for the Hubbard Hamiltonian, the Hubbard Hamiltonian's matrix representation, and the Variational Hamiltonian Ansatz (VHA). As expected, my code and computer's RAM wasn't enough to work with anything more than a 2x2 square lattice (which has 8 qubits, so exists 256-dimensional Hilbert space). What did surprise me was how much more efficient OpenFermion was, because when I tried it when SSHing onto a Google Cloud computer, I was able to quickly solve the ground state of up to a 2x10 square lattice Hubbard Hamiltonian. Most of the functions/classes I defined are still available in the tools/ folder if you want to take a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.optimize \n",
    "\n",
    "from tools.utils import * \n",
    "tol = 0.005 # Tolerance for elementwise equality of matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hubbard-ham\"></a>\n",
    "### Defining the Hubbard Hamiltonian \n",
    "\n",
    "The Hubbard Hamiltonian: \n",
    "$$ H = -t \\sum_{\\braket{j, k}, \\sigma} \\Big( c^\\dagger_{j\\sigma} c_{k\\sigma} + c^\\dagger_{k \\sigma} c_{j \\sigma} \\Big) + U \\sum_j n_{j \\uparrow} n_{j \\downarrow} - \\mu \\sum_j \\Big(n_{j\\uparrow} + n_{j\\downarrow} \\Big) $$\n",
    "\n",
    "The first term is kinetic energy, a fermion moving from one site to another. The symbol $\\braket{j, k}$ implies iterating over sites that are adjacent. \n",
    "\n",
    "The second term is interaction energy, additional energy for a doubly-occupied site. \n",
    "\n",
    "The third term is chemical potential, which controls the filling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Hubbard Hamiltonian on a Square Lattice \n",
    "\n",
    "We'll use OpenFermion's `HubbardSquareLattice` class to define our lattice. OpenFermion has a simpler function `fermi_hubbard()` to create a `FermionOperator` to describe our system, but this doesn't give us access to the specific hopping terms in the Hamiltonian (the terms in the first summation above), which we'll need for the Variational Hamiltonian Ansatz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion.utils import HubbardSquareLattice\n",
    "# HubbardSquareLattice parameters\n",
    "x_n = 2\n",
    "y_n = 2\n",
    "n_dofs = 1 # 1 degree of freedom for spin, this might be wrong. Having only one dof means ordered=False. \n",
    "periodic = 0 # Not sure what this is, periodic boundary conditions?\n",
    "spinless = 0 # Has spin\n",
    "\n",
    "lattice = HubbardSquareLattice(x_n, y_n, n_dofs=n_dofs, periodic=periodic, spinless=spinless)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a `FermiHubbardModel` instance by passing it our `HubbardSquareLattice` instance defined above. \n",
    "\n",
    "To get the `FermionOperator` instance, we need to call `FermiHubbardModel.hamiltonian()`. The [documentation](https://openfermion.readthedocs.io/en/latest/openfermion.html#openfermion.hamiltonians.FermiHubbardModel) isn't that great here, but the [source code](https://github.com/quantumlib/OpenFermion/blob/master/src/openfermion/hamiltonians/_general_hubbard.py) indicates we do indeed get a `FermionOperator` instance which we'll need for calculating ground state, etc. \n",
    "\n",
    "We can't just pass an integer for $t$, $U$, or $\\mu$ in this class. Instead, we have to specify the *specific* coefficient for each pair and edge type ($t_{ij}^{\\textrm{horizontal neighbor}}$). This will be useful later on, I think, because [1506.05135](https://arxiv.org/abs/1506.05135) says we'll need the indices for different values during adiabatic evolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion.hamiltonians import FermiHubbardModel\n",
    "from openfermion.utils import SpinPairs\n",
    "tunneling = [('neighbor', (0, 0), 1.)] # Not sure if this is right\n",
    "interaction = [('onsite', (0, 0), 2., SpinPairs.DIFF)] # Not sure if this is right\n",
    "# potential = [(0, 1.)]\n",
    "potential = None\n",
    "mag_field = 0. \n",
    "particle_hole_sym = False # Not sure if this is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubbard = FermiHubbardModel(lattice , tunneling_parameters=tunneling, interaction_parameters=interaction, \n",
    "                            potential_parameters=potential, magnetic_field=mag_field, \n",
    "                            particle_hole_symmetry=particle_hole_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the values in this dictionary are instances of FermionOperator\n",
    "hamiltonians = {\n",
    "    'hub': hubbard.hamiltonian(), \n",
    "    'non_interacting': hubbard.tunneling_terms()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Hamiltonian Ansatz\n",
    "\n",
    "The VHA is an ansatz inspired by time-evolution of the system. It splits the Hamiltonian into sub-operators and then does time-evolution for those operators: \n",
    "$$\\large U(\\theta) = \\prod_{k=1}^n \\prod_{\\alpha=1}^N \\exp \\Big( i\\theta_{\\alpha, k} H_{\\alpha} \\Big) $$\n",
    "where $H_\\alpha$ are the sub-Hamiltonians and $\\theta$ are the parameters being optimized. \n",
    "\n",
    "**Question:** Why is this a good ansatz? It seems it only has access to states that are evolutions of the state we start with. Why is that a guarantee that it'll approximate the ground state? \n",
    "\n",
    "**Answer:** It's based on adiabatic evolution. I don't understand this but somehow if we start by evolving the ground state of a Hamiltonian (non-interacting part in this case) and then slowly start replacing it with another Hamiltonian (full Hubbard Hamiltonian), we get the corresponding ground state of the new Hamiltonian by magic. \n",
    "\n",
    "In [1811.04476](https://arxiv.org/pdf/1811.04476.pdf) they use $N=5$, splitting it as I did above: even and odd horizontal hopping terms, even and odd vertical horizontal terms, and the on-site interaction terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n",
      "Ground state energy:  -0.9999999999999971\n"
     ]
    }
   ],
   "source": [
    "# Compute ground state on GCloud computers\n",
    "\n",
    "from openfermion import get_sparse_operator, get_ground_state\n",
    "hub_sparse = get_sparse_operator(hamiltonians['hub'])\n",
    "print(hub_sparse.shape)\n",
    "genergy, gstate = get_ground_state(hub_sparse)\n",
    "print(\"Ground state energy: \", genergy)\n",
    "\n",
    "# \"Ground state energy: -3.6272130052966762\" \n",
    "# genergy = -3.6272130052966762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose ground state of tunneling term \n",
    "\n",
    "This isn't that easy - the tunneling sub-Hamiltonian has a degenerate ground state. Adiabatic evolution only works if we start from the ground state of the sub-Hamiltonian that has the same symmetries as the ground state of the Hubbard Hamiltonian, so we need to pick the *right* degenerate ground state. \n",
    "\n",
    "How do we do this? We perturb the tunneling Hamiltonian to get a Hamiltonian $H(s) = H_0 + s H$, where $H_0$ is the tunneling Hamiltonian and $H$ is the Hubbard Hamiltonian, and $s$ is a small number. We find the ground state of this, and then choose the ground state of the tunneling Hamiltonian that has the most overlap with this. \n",
    "\n",
    "To be careful, I pick the top three ground states with highest overlap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is openfermion.get_ground_state() implemented? \n",
    "# They use scipy.sparse.linalg.eigsh \n",
    "\n",
    "def get_k_lowest_eigenvals_states(sparse_hamiltonian, k):\n",
    "    # Find n-2 lowest eigenvalues; there's a bug where it doesn't always find k lowest, so instead \n",
    "    # I find as many as possible, and then choose k lowest from those \n",
    "    n = sparse_hamiltonian.shape[0]\n",
    "    values, vectors = scipy.sparse.linalg.eigsh(\n",
    "        sparse_hamiltonian, k=n-2, which='SA') #'SA' means find k smallest algebraic eigenvalues \n",
    "    order = np.argsort(values)[:k]\n",
    "    values = values[order]\n",
    "    vectors = vectors[:, order]\n",
    "    return values, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowest eigenvalues of Hubbard term - notice no degeneracies\n",
    "w_hub, v_hub = get_k_lowest_eigenvals_states(hub_sparse, 1)\n",
    "w_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.23606798e+00, -1.00000000e+00, -1.00000000e+00, -1.31919123e-16,\n",
       "       -1.50955396e-37,  3.12966036e-21,  2.28239885e-16,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        3.00000000e+00,  3.00000000e+00])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowest eigenvalues of tunneling term \n",
    "tun_sparse = get_sparse_operator(hamiltonians['non_interacting'])\n",
    "# w_tun, v_tun = get_k_lowest_eigenvals_states(tun_sparse, 16)\n",
    "w_tun, v_tun = get_k_lowest_eigenvals_states(hub_sparse, 16)\n",
    "w_tun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion.utils import inner_product\n",
    "def fidelity(a, b): \n",
    "    # Fidelity of pure states \n",
    "    inner = inner_product(a, b)\n",
    "    return np.conjugate(inner) * inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.031569908868109134+0j)\n",
      "(0.04417407280903488+0j)\n",
      "(0.19856207313862317+0j)\n",
      "(0.03418121825354631+0j)\n",
      "(0.046607917333998376+0j)\n",
      "(0.12622062025255382+0j)\n",
      "(0.10964243588147862+0j)\n",
      "(0.03324514709471281+0j)\n",
      "(0.04404955460026721+0j)\n",
      "(0.007748407683286344+0j)\n",
      "(0.07744523099395186+0j)\n",
      "(0.07668760819445185+0j)\n",
      "(0.04117657574101663+0j)\n",
      "(0.04539101349590707+0j)\n",
      "(0.05627848196905416+0j)\n",
      "(0.0031673222112651384+0j)\n"
     ]
    }
   ],
   "source": [
    "# Now for these 16 states, calculate fidelity with ground state of Hubbard \n",
    "for i in range(len(w_tun)):\n",
    "    # Make sure we're using smallest eigenvalue\n",
    "    assert np.abs(w_tun[i] + 4) < tol \n",
    "    print(fidelity(v_tun[:,i], v_hub[:,0]))\n",
    "\n",
    "# We don't have any huge overlaps with ground state... the largest are about 0.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the degenerate ground states of the tunneling term is a clear winner for which we should use the initial state for VHA. Instead, let's try doing a perturbation where we add a \"tiny part\" of the actual Hubbard Hamiltonian to the tunneling Hamiltonian. \n",
    "\n",
    "**Why** does this work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9770315586987662+0j)\n",
      "(2.857868754197029e-25+0j)\n",
      "(9.808775157532961e-21+0j)\n",
      "(3.420337577088862e-22+0j)\n",
      "(9.265386476972156e-26+0j)\n",
      "(4.067753758731241e-23+0j)\n",
      "(1.3378241573817747e-25+0j)\n",
      "(5.503613711534729e-22+0j)\n",
      "(5.03638503889704e-27+0j)\n",
      "(9.286993624191618e-23+0j)\n",
      "(4.378173186744333e-23+0j)\n",
      "(1.0750763967486153e-25+0j)\n",
      "(4.245762078720618e-27+0j)\n",
      "(6.357768930767689e-22+0j)\n",
      "(1.0396924522375917e-26+0j)\n",
      "(2.3137316358585444e-26+0j)\n"
     ]
    }
   ],
   "source": [
    "s = 1e-4\n",
    "perturbed = tun_sparse + s * hub_sparse\n",
    "\n",
    "w_per,v_per = get_k_lowest_eigenvals_states(perturbed, 16)\n",
    "for i in range(len(w_per)):\n",
    "    # Make sure we're using smallest eigenvalue\n",
    "    assert np.abs(w_per[i] + 4) < tol\n",
    "    print(fidelity(v_per[:,i], v_hub[:,0]))\n",
    "    \n",
    "# WOW, there's a clear winner here v_per[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tunneling ground state with most overlap is v_tun[:, 2], which has an overlap of 20.32%.\n"
     ]
    }
   ],
   "source": [
    "# We know that v_per[:, 0] is the ground state that has most overlap with our final ground state \n",
    "# But v_per[:, 0] is an eigenvector of the perturbed Hamiltonian. \n",
    "# Now, we find the tunneling ground state that has most overlap with the perturbed ground state. \n",
    "\n",
    "overlaps = []\n",
    "for i in range(len(w_tun)):\n",
    "    overlaps.append(fidelity(v_tun[:,i], v_per[:,0]).real)\n",
    "max_i = np.argmax(overlaps)\n",
    "max_overlap_state = v_tun[:, max_i]\n",
    "\n",
    "print(\"The tunneling ground state with most overlap is v_tun[:, {}], which has an overlap of {}%.\".format(\n",
    "    max_i, 100 * round(overlaps[max_i], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.00000000e+00, -2.00000000e+00, -1.91765100e-16,  1.64346022e-32,\n",
       "        8.93943564e-17,  5.82889146e-16,  2.00000000e+00,  2.00000000e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To pick a specific degenerate ground state, we must specify the orbital_energies. See: \n",
    "# https://github.com/quantumlib/OpenFermion/issues/284#issuecomment-375832824\n",
    "from openfermion import QuadraticHamiltonian,  get_diagonal_coulomb_hamiltonian\n",
    "\n",
    "# Convert to DiagonalCoulombHamiltonian \n",
    "# I think this is because the ansatz uses properties of this?\n",
    "dc_hub = get_diagonal_coulomb_hamiltonian(hamiltonians['hub'])\n",
    "\n",
    "orbital_energies, constant = QuadraticHamiltonian(dc_hub.one_body).orbital_energies()\n",
    "orbital_energies\n",
    "# Okay so we need to include 0 and 1 because those give us -4, but then we can include any subset of \n",
    "# the 4 values that are 0, so we have 2^4 = 16 possible ground states like we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get all possible combinations of our orbital energies, so we can try them all \n",
    "\n",
    "import itertools \n",
    "zero_indices = [2,3,4,5]\n",
    "orbital_energies_combs = []\n",
    "for r in range(len(zero_indices) + 1):\n",
    "    for subset in itertools.combinations(zero_indices, r):\n",
    "        orbital_energies_combs.append([0, 1] + list(subset))\n",
    "# Checking we have correct subsets\n",
    "for comb in orbital_energies_combs:\n",
    "    total = 0\n",
    "    for i in comb: \n",
    "        total += orbital_energies[i]\n",
    "    assert np.abs(total + 4) < tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 fidelities are:  [0.2032311 +0.j 0.1863635 +0.j 0.15893537+0.j]\n"
     ]
    }
   ],
   "source": [
    "# We generate each ground state, and then compare the state vector to our desired \n",
    "# tunneling ground state vector. This way we know which orbital_energies configuration \n",
    "# will reproduce it.\n",
    "from openfermioncirq import prepare_gaussian_state\n",
    "\n",
    "from cirq import Circuit, final_wavefunction, LineQubit\n",
    "gstates = []\n",
    "fidelities = []\n",
    "for i in range(len(orbital_energies_combs)):\n",
    "    degen_gstate = final_wavefunction(\n",
    "        Circuit(\n",
    "            prepare_gaussian_state(\n",
    "                # We choose start state to be ground state of tunneling terms\n",
    "                # But isn't this degenerate?\n",
    "                LineQubit.range(8), \n",
    "                QuadraticHamiltonian(dc_hub.one_body), \n",
    "                occupied_orbitals = orbital_energies_combs[i]\n",
    "            ))\n",
    "    )\n",
    "    \n",
    "    gstates.append(degen_gstate)\n",
    "    \n",
    "    fidelities.append(fidelity(degen_gstate, max_overlap_state))\n",
    "\n",
    "# Pick top 3 fidelities: I reverse np.argsort, then choose first 3\n",
    "top_three = np.argsort(fidelities)[::-1][:3]\n",
    "fidelities = np.array(fidelities)[top_three]\n",
    "gstates = np.array(gstates)[:, top_three]\n",
    "print(\"Top 3 fidelities are: \", fidelities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running VQE\n",
    "\n",
    "Now, we try each of these 3 ground states. One of them is probably the one that adiabatically evolves to the Hubbard ground state. \n",
    "\n",
    "I end up needing to rewrite most of the `SwapNetworkTrotterAnsatz` from OpenFermion to get more control over our initialization strategy. [1811.04476](https://arxiv.org/abs/1811.04476) says initial parameters turned out to be very important for reaching the ground state, and they were able to get 100% overlap on the 2x2 Hubbard model, so I'll try their strategies. \n",
    "\n",
    "Refer to the docstrings for more info on implementation, but broadly, the initialization strategies are: \n",
    "- Adiabatically turn on the interacting term \n",
    "- Adiabatically turn on the tunneling and interaction terms \n",
    "- Trotter expansion where all parameters are the same \n",
    "- Adiabatically turn on interaction for shorter time. \n",
    "\n",
    "We also try to implement the \"full optimization\" method outlined in [1506.05135](https://arxiv.org/abs/1506.05135). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple callback function we can pass into the optimizer to tell us what iteration it's on\n",
    "# Nevermind: this doesn't work with study.save()\n",
    "def gen_callback():\n",
    "    i = 0 \n",
    "    def callback(xk):\n",
    "        nonlocal i\n",
    "        print(\"Iteration: \", i)\n",
    "        i += 1\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermioncirq import SwapNetworkTrotterHubbardAnsatz\n",
    "\n",
    "class CustomHubbard(SwapNetworkTrotterHubbardAnsatz):\n",
    "    # Redefining my own Hubbard ansatz to override default_initial_params(self) \n",
    "    def __init__(self,\n",
    "                 x_dim: float,\n",
    "                 y_dim: float,\n",
    "                 tunneling: float,\n",
    "                 coulomb: float,\n",
    "                 initial_param_method: str, # This is the only change! \n",
    "                 periodic: bool=True,\n",
    "                 iterations: int=1,\n",
    "                 adiabatic_evolution_time=None,\n",
    "                 qubits=None\n",
    "                 ) -> None:\n",
    "        \n",
    "        possible_initial_param_methods = [\n",
    "            'adiabatic', 'adiabatic_tunneling', 'trotter_constant', 'adiabatic_short'\n",
    "        ]\n",
    "        if initial_param_method not in possible_initial_param_methods:\n",
    "            raise ValueError('initial_param_method must be one of {}'.format(possible_initial_param_methods))\n",
    "        self.initial_param_method = initial_param_method\n",
    "        \n",
    "        super().__init__(x_dim, y_dim, tunneling, coulomb, periodic=periodic, iterations=iterations, \n",
    "                         adiabatic_evolution_time=adiabatic_evolution_time, qubits=qubits)\n",
    "        \n",
    "    def default_initial_params(self):\n",
    "        total_time = self.adiabatic_evolution_time\n",
    "        step_time = total_time / self.iterations \n",
    "        \n",
    "        params = [] \n",
    "        # I'm going to keep the format of the original default_initial_params (the -self.tunneling and \n",
    "        # division by pi) even though I don't understand why they do this yet. \n",
    "        if self.initial_param_method == 'adiabatic': \n",
    "            \"\"\"\n",
    "            Approximate evolution by H(t) = T + (t/A)V.\n",
    "            Sets the parameters so that the ansatz circuit consists of a sequence\n",
    "            of second-order Trotter steps approximating the dynamics of the\n",
    "            time-dependent Hamiltonian H(t) = T + (t/A)V, where T is the one-body\n",
    "            term and V is the two-body term of the Hamiltonian used to generate the\n",
    "            ansatz circuit, and t ranges from 0 to A, where A is equal to\n",
    "            `self.adibatic_evolution_time`. The number of Trotter steps\n",
    "            is equal to the number of iterations in the ansatz. This choice is\n",
    "            motivated by the idea of state preparation via adiabatic evolution.\n",
    "            The dynamics of H(t) are approximated as follows. First, the total\n",
    "            evolution time of A is split into segments of length A / r, where r\n",
    "            is the number of Trotter steps. Then, each Trotter step simulates H(t)\n",
    "            for a time length of A / r, where t is the midpoint of the\n",
    "            corresponding time segment. As an example, suppose A is 100 and the\n",
    "            ansatz has two iterations. Then the approximation is achieved with two\n",
    "            Trotter steps. The first Trotter step simulates H(25) for a time length\n",
    "            of 50, and the second Trotter step simulates H(75) for a time length\n",
    "            of 50.\n",
    "\n",
    "            The above docstring was copied from OpenFermion. \n",
    "            \"\"\"\n",
    "            for param, scale_factor in zip(self.params(),\n",
    "                                           self.param_scale_factors()):\n",
    "                if param.letter == 'Th' or param.letter == 'Tv':\n",
    "                    params.append(_canonicalize_exponent(\n",
    "                        -self.tunneling * step_time / np.pi, 4) / scale_factor)\n",
    "                elif param.letter == 'V':\n",
    "                    i, = param.subscripts\n",
    "                    # Use the midpoint of the time segment\n",
    "                    interpolation_progress = 0.5 * (2 * i + 1) / self.iterations\n",
    "                    params.append(_canonicalize_exponent(\n",
    "                        -0.5 * self.coulomb * interpolation_progress *\n",
    "                        step_time / np.pi, 2) / scale_factor)\n",
    "\n",
    "        elif self.initial_param_method == 'adiabatic_tunneling': \n",
    "            \"\"\"\n",
    "            Instead of only adiabatically turning on the interaction term, we also \n",
    "            adiabatically turn on the tunneling term. \n",
    "            \n",
    "            Inspired by 1811.04476. \n",
    "            \"\"\"\n",
    "            for param, scale_factor in zip(self.params(),\n",
    "                                           self.param_scale_factors()):\n",
    "                i, = param.subscripts\n",
    "                # Use the midpoint of the time segment\n",
    "                interpolation_progress = 0.5 * (2 * i + 1) / self.iterations\n",
    "\n",
    "                if param.letter == 'Th' or param.letter == 'Tv':\n",
    "                    params.append(_canonicalize_exponent(\n",
    "                        -self.tunneling * interpolation_progress * \n",
    "                        step_time / np.pi, 4) / scale_factor)\n",
    "                elif param.letter == 'V':\n",
    "                    params.append(_canonicalize_exponent(\n",
    "                        -0.5 * self.coulomb * interpolation_progress *\n",
    "                        step_time / np.pi, 2) / scale_factor)\n",
    "        \n",
    "        elif self.initial_param_method == 'trotter_constant': \n",
    "            \"\"\"\n",
    "            This is just Trotter decomposition for a simulation of length total_time. \n",
    "            I don't use _canonicalize_exponent(), so check what changes and if anything breaks. \n",
    "            \n",
    "            Inspired by 1811.04476.\n",
    "            \"\"\"\n",
    "            for param, scale_factor in zip(self.params(),\n",
    "                                           self.param_scale_factors()):\n",
    "                params.append(step_time)\n",
    "\n",
    "        elif self.initial_param_method == 'adiabatic_short':\n",
    "            \"\"\"\n",
    "            OpenFermion sets adiabatic_evolution_time = 0.1*abs(coulomb)*iterations, if we don't \n",
    "            provide one ourselves. This initialization method will divide that by iterations. \n",
    "            \n",
    "            Inspired by 1811.04476. \n",
    "            \"\"\"\n",
    "            total_time /= 5\n",
    "            step_time /= 5\n",
    "            for param, scale_factor in zip(self.params(),  self.param_scale_factors()):\n",
    "                # Copied 'adiabatic'\n",
    "                if param.letter == 'Th' or param.letter == 'Tv':\n",
    "                    params.append(_canonicalize_exponent(\n",
    "                        -self.tunneling * step_time / np.pi, 4) / scale_factor)\n",
    "                elif param.letter == 'V':\n",
    "                    i, = param.subscripts\n",
    "                    # Use the midpoint of the time segment\n",
    "                    interpolation_progress = 0.5 * (2 * i + 1) / self.iterations\n",
    "                    params.append(_canonicalize_exponent(\n",
    "                        -0.5 * self.coulomb * interpolation_progress *\n",
    "                        step_time / np.pi, 2) / scale_factor)\n",
    "                    \n",
    "        else: \n",
    "            raise ValueError(\"Don't know how to interpret initial parameter method {}\".format(self.initial_param_method))\n",
    "\n",
    "        return np.array(params)\n",
    "    \n",
    "def _canonicalize_exponent(exponent: float, period: int) -> float:\n",
    "    # Shift exponent into [-p/2, +p/2).\n",
    "    # They chose period = bounds (4 for T, 2 for V)\n",
    "    exponent += period / 2\n",
    "    exponent %= period\n",
    "    exponent -= period / 2\n",
    "    # Prefer (-p/2, +p/2] over [-p/2, +p/2).\n",
    "    if exponent <= -period / 2:\n",
    "        exponent += period  # coverage: ignore\n",
    "    return exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermioncirq import HamiltonianObjective, VariationalStudy\n",
    "from openfermioncirq.optimization import ScipyOptimizationAlgorithm, OptimizationParams\n",
    "from datetime import datetime\n",
    "\n",
    "# Optimizes and saves our VariationalStudy\n",
    "def run_ansatz(index_orbital_energies_combs, initialization_strat):\n",
    "    steps = 10\n",
    "    \n",
    "    obj = HamiltonianObjective(dc_hub) # Define objective function as Hamiltonian averaging\n",
    "    \n",
    "#     ansatz = SwapNetworkTrotterHubbardAnsatz(x_n, y_n, 1., 2., periodic=False, iterations=steps)\n",
    "    ansatz = CustomHubbard(x_n, y_n, 1., 2., initialization_strat, periodic=False, iterations=steps, \n",
    "                           adiabatic_evolution_time=50.)\n",
    "    \n",
    "    prep_circ = Circuit(\n",
    "        prepare_gaussian_state(\n",
    "            ansatz.qubits, \n",
    "            QuadraticHamiltonian(dc_hub.one_body), \n",
    "            occupied_orbitals=orbital_energies_combs[index_orbital_energies_combs]\n",
    "        ))\n",
    "    time = datetime.now().strftime(\"%m.%d.%y-%H:%M:%S\")\n",
    "    study = VariationalStudy(\n",
    "        'Hubbard-VHA-{}-{}-{}'.format(index_orbital_energies_combs, initialization_strat, time), \n",
    "        ansatz, \n",
    "        obj, \n",
    "        preparation_circuit=prep_circ, \n",
    "        target=genergy, \n",
    "        datadir='SavedVariationalStudy'\n",
    "    )\n",
    "    \n",
    "    algorithm = ScipyOptimizationAlgorithm(\n",
    "        kwargs={'method': 'L-BFGS-B', \n",
    "#                 'tol': 1e-16\n",
    "               }, \n",
    "#         options={'maxiter': 100}, \n",
    "        uses_bounds=True)\n",
    "    \n",
    "    optimizaton_params = OptimizationParams(algorithm=algorithm)\n",
    "    \n",
    "    # Optimize\n",
    "    result = study.optimize(optimizaton_params)\n",
    "    \n",
    "    study.save()\n",
    "    return result.optimal_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-cffaa6b1191b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minit_strat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'adiabatic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adiabatic_tunneling'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trotter_constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adiabatic_short'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         print(\"For tunneling ground state with index {} and initialization strategy {},the Hubbard ground state energy is {}\".format(\n\u001b[0;32m----> 4\u001b[0;31m             i, init_strat, run_ansatz(i, init_strat)))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# We don't see that much improvement...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9ac0f3233124>\u001b[0m in \u001b[0;36mrun_ansatz\u001b[0;34m(index_orbital_energies_combs, initialization_strat)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizaton_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/variational/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, optimization_params, identifier, reevaluate_final_params, save_x_vals, repetitions, seeds, use_multiprocessing, num_processes)\u001b[0m\n\u001b[1;32m    171\u001b[0m                                    \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                                    \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                                    num_processes)[0]\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     def optimize_sweep(self,\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/variational/study.py\u001b[0m in \u001b[0;36moptimize_sweep\u001b[0;34m(self, param_sweep, identifiers, reevaluate_final_params, save_x_vals, repetitions, seeds, use_multiprocessing, num_processes)\u001b[0m\n\u001b[1;32m    257\u001b[0m                         \u001b[0mseeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                         num_processes)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 trial_result = OptimizationTrialResult(result_list,\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/variational/study.py\u001b[0m in \u001b[0;36m_get_result_list\u001b[0;34m(self, optimization_params, reevaluate_final_params, save_x_vals, repetitions, seeds, use_multiprocessing, num_processes)\u001b[0m\n\u001b[1;32m    423\u001b[0m                         \u001b[0;32melse\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4294967296\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mansatz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_initial_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_black_box_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m                     )\n\u001b[1;32m    427\u001b[0m                 )\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/variational/study.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    619\u001b[0m     result = optimization_params.algorithm.optimize(black_box,\n\u001b[1;32m    620\u001b[0m                                                     \u001b[0minitial_guess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                                                     initial_guess_array)\n\u001b[0m\u001b[1;32m    622\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/optimization/scipy.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, black_box, initial_guess, initial_guess_array)\u001b[0m\n\u001b[1;32m     57\u001b[0m                                          \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                          \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                                          **self.kwargs)\n\u001b[0m\u001b[1;32m     60\u001b[0m         return OptimizationResult(optimal_value=result.fun,\n\u001b[1;32m     61\u001b[0m                                   \u001b[0moptimal_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/optimization/black_box.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_of_evaluate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_with_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_of_evaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     def evaluate_with_cost(self,\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/variational/variational_black_box.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"\"\"Determine the value of some parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Default: defer to evaluate_noiseless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_noiseless\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     def _evaluate_with_cost(self,\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/openfermioncirq/variational/variational_black_box.py\u001b[0m in \u001b[0;36mevaluate_noiseless\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         circuit = cirq.resolve_parameters(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreparation_circuit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mansatz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 self.ansatz.param_resolver(x))\n\u001b[0m\u001b[1;32m     97\u001b[0m         final_state = circuit.final_wavefunction(\n\u001b[1;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/protocols/resolve_parameters.py\u001b[0m in \u001b[0;36mresolve_parameters\u001b[0;34m(val, param_resolver)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_resolve_parameters_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotImplemented\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_resolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/circuits/circuit.py\u001b[0m in \u001b[0;36m_resolve_parameters_\u001b[0;34m(self, param_resolver)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             resolved_operations = _resolve_operations(\n\u001b[1;32m   1613\u001b[0m                 \u001b[0mmoment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m                 param_resolver)\n\u001b[0m\u001b[1;32m   1615\u001b[0m             \u001b[0mnew_moment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMoment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_operations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m             \u001b[0mresolved_moments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_moment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/circuits/circuit.py\u001b[0m in \u001b[0;36m_resolve_operations\u001b[0;34m(operations, param_resolver)\u001b[0m\n\u001b[1;32m   1721\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m         resolved_operations.append(protocols.resolve_parameters(\n\u001b[0;32m-> 1723\u001b[0;31m             op, param_resolver))\n\u001b[0m\u001b[1;32m   1724\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresolved_operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/protocols/resolve_parameters.py\u001b[0m in \u001b[0;36mresolve_parameters\u001b[0;34m(val, param_resolver)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_resolve_parameters_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotImplemented\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_resolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/ops/gate_operation.py\u001b[0m in \u001b[0;36m_resolve_parameters_\u001b[0;34m(self, resolver)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resolve_parameters_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mresolved_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotocols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mGateOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/protocols/resolve_parameters.py\u001b[0m in \u001b[0;36mresolve_parameters\u001b[0;34m(val, param_resolver)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_resolve_parameters_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotImplemented\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_resolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/ops/eigen_gate.py\u001b[0m in \u001b[0;36m_resolve_parameters_\u001b[0;34m(self, param_resolver)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resolve_parameters_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTSelf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_resolver\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         return self._with_exponent(\n\u001b[0;32m--> 323\u001b[0;31m                 exponent=param_resolver.value_of(self._exponent))\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_equal_up_to_global_phase_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/cirq/study/resolver.py\u001b[0m in \u001b[0;36mvalue_of\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# only use it for cases that require complicated resolution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_symbols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/sympy/core/basic.py\u001b[0m in \u001b[0;36msubs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                 s = [sympify(_, strict=not isinstance(_, string_types))\n\u001b[0;32m--> 951\u001b[0;31m                      for _ in s]\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSympifyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;31m# if it can't be sympified, skip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/sympy/core/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                 s = [sympify(_, strict=not isinstance(_, string_types))\n\u001b[0;32m--> 951\u001b[0;31m                      for _ in s]\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSympifyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;31m# if it can't be sympified, skip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/sympy/core/sympify.py\u001b[0m in \u001b[0;36msympify\u001b[0;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msuperclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetmro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msuperclass\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/sympy/core/numbers.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# support for numpy datatypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/sympy/core/sympify.py\u001b[0m in \u001b[0;36m_convert_numpy_types\u001b[0;34m(a, **sympify_args)\u001b[0m\n\u001b[1;32m     70\u001b[0m             a = str(list(np.reshape(np.asarray(a),\n\u001b[1;32m     71\u001b[0m                                     (1, np.size(a)))[0]))[1:-1]\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             raise SympifyError('Translation for numpy float : %s '\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/sympy/core/numbers.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0m_mpf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m             \u001b[0m_mpf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/qc-mentorship/env/lib/python3.6/site-packages/mpmath/libmp/libmpf.py\u001b[0m in \u001b[0;36mfrom_str\u001b[0;34m(x, prec, rnd)\u001b[0m\n\u001b[1;32m   1340\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mman\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_rational\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in top_three:\n",
    "    for init_strat in ['adiabatic', 'adiabatic_tunneling', 'trotter_constant', 'adiabatic_short']:\n",
    "        print(\"For tunneling ground state with index {} and initialization strategy {},the Hubbard ground state energy is {}\".format(\n",
    "            i, init_strat, run_ansatz(i, init_strat)))\n",
    "\n",
    "# We don't see that much improvement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "path = 'SavedVariationalStudy/' + os.listdir('SavedVariationalStudy')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# So once we do that optimization, we have decent overlap and we have our parameters. \n",
    "\"\"\"\n",
    "It seems they do an iterated VQE: do VQE for H(1/s) using ground state of H(0), then do VQE for H(2/s) using \n",
    "ground state of H(1/s), ..., until they solve VQE for H(1). They call this the result of \"sequential optimization\"\n",
    "and it isn't *that* close to the ground state (~70% overlap for 3 iterations with 2x2). \n",
    "Then, they used these resulting parameters as the initial parameters for an optimization method they call the \n",
    "\"global vairational\" method, calling this final result \"full optimziation\". \n",
    "Here's what the global variational method does: \n",
    "1. Choose 6 random points near the initial parameters\n",
    "2. For each point, do greedy noisy search for 150 iterations: \n",
    "    a. slightly perturb point\n",
    "        i. If number of acceptances in last 30 trials was large, increase step size. Else, decrease it. \n",
    "    b. keep the new value if it reduces energy\n",
    "3. Do Powell on each point until convergence. \n",
    "4. Keep the point with lowest energy. \n",
    "5. Alternate greedy noisy search and Powell until neither finds improvement. \n",
    "\"\"\"\n",
    "\n",
    "# study = VariationalStudy.load('SavedVariationalStudy/Hubbard-VHA-0-adiabatic-5.13.20-09:39:03')\n",
    "study = VariationalStudy.load(path)\n",
    "params = study.trial_results[0].optimal_parameters \n",
    "\n",
    "def init_6(params):\n",
    "    \"\"\"Initialize 6 'points' that we optimize. Step 1 above. \"\"\"\n",
    "    new_points = [] \n",
    "    for i in range(6):\n",
    "        gaussian_noise = np.random.normal(size=params.size) \n",
    "        new_points.append(params + gaussian_noise)\n",
    "    return new_points\n",
    "\n",
    "def greedy_noisy_search(point, iterations=150):\n",
    "    \"\"\"Do greedy noisy search as described above. \"\"\"\n",
    "    min_point = point\n",
    "    values = []\n",
    "    # Standard deviation of noise - this might not work \n",
    "    step_size = 0.5\n",
    "    for i in range(iterations):\n",
    "        gaussian_noise = np.random.normal(scale=step_size, size=point.size)\n",
    "        # Get value of new parameters\n",
    "        new_val = study.value_of(point + gaussian_noise)\n",
    "        values.append(new_val) \n",
    "        if new_val == min(values): \n",
    "            step_size /= 0.8 \n",
    "            min_point = new_val\n",
    "            print('Minimum is now {}'.format(min_point))\n",
    "        elif np.random.randint(20) == 0: # Do this 1/20 times\n",
    "            step_size *= 0.8\n",
    "        print(i, step_size)\n",
    "    return min_point\n",
    "\n",
    "def powell(point):\n",
    "    res = scipy.optimize.minimize(study.value_of, point, method='Powell', tol=1e-10)\n",
    "    return res.x.real\n",
    "\n",
    "def full_optimization(params):\n",
    "    six_starter_points = init_6(params)\n",
    "    for i in range(len(six_starter_points)):\n",
    "        six_starter_points[i] = greedy_noisy_search(six_starter_points[i])\n",
    "#         six_starter_points[i] = powell(six_starter_points[i])\n",
    "        print(six_starter_points[i])\n",
    "    vals = [study.value_of(point) for point in six_starter_points]\n",
    "    \n",
    "    try:\n",
    "        best = six_starter_points[np.argmin(vals)]\n",
    "        best_val = study.value_of(best)\n",
    "        curr = 'greedy'\n",
    "        while True: \n",
    "            old_best = best\n",
    "            if curr == 'greedy':\n",
    "                best = greedy_noisy_search(best)\n",
    "                curr = 'powell'\n",
    "            else: \n",
    "                best = powell(best)\n",
    "                curr = 'greedy'\n",
    "            if np.abs(study.value_of(best) - study.value_of(old_best)) < 1e-10:\n",
    "                break \n",
    "    except:\n",
    "        return best\n",
    "    return best\n",
    "            \n",
    "            \n",
    "full_optimization(params)\n",
    "# Errors when I run Powell... but either way not seeing much improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we have an error of about 0.12. I suspect this might be the Trotter error, which means Jan-Michael's \n",
    "# decomposition will fix it. If it does, then I am justified in working on measurement precision. \n",
    "# For now, let's check the overlap with our true ground state\n",
    "\n",
    "from cirq import resolve_parameters\n",
    "from openfermioncirq.variational import variational_black_box\n",
    "\n",
    "def get_optimal_ground_state(study): \n",
    "    # Modified variational_black_box.UNITARY_SIMULATE.evaluate_noiseless \n",
    "    black_box = study._black_box_type(\n",
    "        study.ansatz, \n",
    "        study.objective, \n",
    "        study._preparation_circuit, \n",
    "        study.initial_state)\n",
    "    \n",
    "    circuit = resolve_parameters(\n",
    "        black_box.preparation_circuit + black_box.ansatz.circuit, \n",
    "        black_box.ansatz.param_resolver(black_box.ansatz.default_initial_params()))\n",
    "    final_state = circuit.final_wavefunction(\n",
    "        black_box.initial_state, \n",
    "        qubit_order=black_box.ansatz.qubit_permutation(black_box.ansatz.qubits))\n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STUDY WITH BEST VALUE AND CHECK FIDELITY\n",
    "study = VariationalStudy.load(path)\n",
    "\n",
    "opt_ground = get_optimal_ground_state(study)\n",
    "fidelity(opt_ground, v_hub[:,0]).real\n",
    "# 97.7% fidelity is great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we implement the above exponentials in a quantum circuit? Hm... \n",
    "\n",
    "OF has a `SwapNetworkTrotterHubbard` ansatz. How does it work? \n",
    "\n",
    "Well, the SwapNetwork uses only `ISWAP`, `PhasedISWAP`, `CZ` and `Z` gates. What does it do? \n",
    "\n",
    "It was proposed in arxiv: 1711.04789. It allows us to simulate a Trotter step in $N$ depth and $N^2 / 2$ two-qubit entangling gates, and lets us prepare arbitrary Slater determinants in $N/2$ depth, all assuming only a linearly connected architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Btw, this our ansatz\n",
    "print('Created a variational study with {} qubits and {} parameters'.format(\n",
    "    len(study.ansatz.qubits), study.num_params))\n",
    "\n",
    "print(\"The value of the objective with default initial parameters is {}\".format(\n",
    "    study.value_of(ansatz.default_initial_params())))\n",
    "\n",
    "print(\"The circuit of the study is:\")\n",
    "print(study.circuit.to_text_diagram(transpose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the circuit is made up of only 2 main gates: `ISWAPPowGate` and `CZPowGate`. The Cirq documentation tells us that the matrix decomposition for these gates is: \n",
    "$$\\texttt{ISWAPPowGate}(t) = \\begin{bmatrix} \n",
    "1 & 0 & 0 & 0 \\\\ \n",
    "0 & \\cos(\\frac{\\pi t}{2}) & i \\sin \\frac{\\pi t}{2} & 0 \\\\\n",
    "0 & i \\sin(\\frac{\\pi t}{2}) & \\cos(\\frac{\\pi t}{2}) & 0 \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{bmatrix} \\qquad \\texttt{CZPowGate}(t) = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & \\exp(i \\pi t) \n",
    "\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We have 60 parameters. What are they? \n",
    "# They're in format (U/T/W/V, p, q, i) where p,q are qubits and i is iteration\n",
    "# Seems 12 parameters per iteration. Per iteration, 4 interaction terms like we'd expect, \n",
    "# and then 8 tunneling terms like we'd expect. \n",
    "\n",
    "# How can I make these fewer? YO, SwapNetworkTrotterHubbard has only 3 parameters per iteration!\n",
    "list(ansatz.params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this mean?\n",
    "obj.variance_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking commutator relations of JW for Trotterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion.utils import commutator \n",
    "from openfermion.ops import FermionOperator \n",
    "from openfermion.transforms import jordan_wigner \n",
    "\n",
    "tunneling_01 = FermionOperator('0^ 1') + FermionOperator('1^ 0')\n",
    "tunneling_12 = FermionOperator('1^ 2') + FermionOperator('2^ 1')\n",
    "tunneling_23 = FermionOperator('2^ 3') + FermionOperator('3^ 2')\n",
    "\n",
    "print('Commutator of 01 and 12 is: ', commutator(tunneling_01, tunneling_12))\n",
    "print('\\nJW matrix of above commutator is: ', commutator(jordan_wigner(tunneling_01), jordan_wigner(tunneling_12)))\n",
    "print('\\nCommutator of 01 and 23 is: ', commutator(tunneling_01, tunneling_23))\n",
    "print('\\nJW matrix of above commutator is: ', commutator(jordan_wigner(tunneling_01), jordan_wigner(tunneling_23)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jordan_wigner(FermionOperator('1^')) * jordan_wigner(FermionOperator('0^'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.25 * NKron(X, X) + 0.25 * NKron(X, Y) + 0.25 * NKron(Y, X) + 0.25 * NKron(Y, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to reduce Trotter error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HubbardSquareLattice` class has a useful method: `site_pair_iter(edge_type)`. We'll use the 'horizontal_neighbor' and 'vertical_neighbor' edge types. But we also need to differentiate between \"even\" and \"odd\" horizontal and vertical neighbors: even horizontal neighbors will be horizontal neighbors whose leftmost site has even index, and likewise for horizontal odd, vertical even, and vertical odd neighbors. To get this added specificity, we'll need to examine each item in the iterable generated by `site_pair_iter()`. We need the even and odd terms because then when we Trotterize the Hubbard Hamiltonian, we don't introduce any Trotter error, because the our four sets of tunneling terms (even horizontal, even vertical, odd horizontal, odd vertical) commute with each other. \n",
    "\n",
    "Actually, it will be much easier to just subclass `HubbardSquareLattice` and define our own `site_pair_iter()` that allows us to specify 'even' or 'odd'. I'll call this class `DecomposedHubbardSquareLattice`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "class DecomposedHubbardSquareLattice(HubbardSquareLattice):\n",
    "    @property \n",
    "    def edge_types(self):\n",
    "        # Overriding edge_types property so we can define additional ones \n",
    "        return ('onsite', 'neighbor', 'diagonal_neighbor', 'horizontal_neighbor', 'vertical_neighbor', \n",
    "                'hor_even_neighbor', 'hor_odd_neighbor', 'ver_even_neighbor', 'ver_odd_neighbor')\n",
    "        \n",
    "    def site_pairs_iter(self, edge_type, ordered=True):\n",
    "        # `ordered` parameter just flips the order: if True, for each a,b -> (a,b), (b,a); if False, for each \n",
    "        # a,b -> (a,b), so we only get it once and it doesn't flip order. \n",
    "        # We WANT ordered=False, because there's a helper function tunneling_operator(i, j, coeff) that takes in \n",
    "        # two sites i,j and does coeff*(i^j j^i). \n",
    "        \n",
    "        # Overriding site_pairs_iter() to add functionality for additional edge_types \n",
    "        if edge_type == 'onsite':\n",
    "            return ((i, i) for i in self.site_indices)\n",
    "        elif edge_type == 'neighbor':\n",
    "            return self.neighbors_iter(ordered)\n",
    "        elif edge_type == 'horizontal_neighbor':\n",
    "            return self.horizontal_neighbors_iter(ordered)\n",
    "        elif edge_type == 'vertical_neighbor':\n",
    "            return self.vertical_neighbors_iter(ordered)\n",
    "        elif edge_type == 'diagonal_neighbor':\n",
    "            return self.diagonal_neighbors_iter(ordered)\n",
    "        # Above was copied from utils._lattice.py so we handle old edge_types correctly. \n",
    "        # Below is added functionality for new edge_types. \n",
    "        elif edge_type == 'hor_even_neighbor':\n",
    "            return self.hv_eo_neighbors(lambda x,y: 1-x%2, lambda x,y: (x+1, y), ordered) \n",
    "        elif edge_type == 'hor_odd_neighbor':\n",
    "            return self.hv_eo_neighbors(lambda x,y: x%2, lambda x,y: (x+1, y), ordered)\n",
    "        elif edge_type == 'ver_even_neighbor':\n",
    "            return self.hv_eo_neighbors(lambda x,y: 1-y%2, lambda x,y: (x, y+1), ordered)\n",
    "        elif edge_type == 'ver_odd_neighbor':\n",
    "            return self.hv_eo_neighbors(lambda x,y: y%2, lambda x,y: (x, y+1), ordered)\n",
    "        raise ValueError('Edge type {} is not valid.'.format(edge_type))\n",
    "        \n",
    "    def hv_eo_neighbors(self, filter_xy, map_next_xy, ordered=True):\n",
    "        for i in range(self.x_dimension):\n",
    "            for j in range(self.y_dimension):\n",
    "                if filter_xy(i, j):\n",
    "                    # Get indices for next site  \n",
    "                    k, l = map_next_xy(i, j)\n",
    "                    # Make sure next site isn't out of bounds \n",
    "                    if k >= self.x_dimension or l >= self.y_dimension: continue \n",
    "                    \n",
    "                    site_a = self.to_site_index((i, j))\n",
    "                    site_b = self.to_site_index((k, l))\n",
    "                    \n",
    "                    yield (site_a, site_b)\n",
    "                    if ordered: yield (site_b, site_a)\n",
    "        \n",
    "    # Function OpenFermion uses for 'horizontal_neightbor' edge_type.  \n",
    "    # PROBLEM: This loops around! Notice the % self.x_dimension. \n",
    "    def horizontal_neighbors_iter(self, ordered=True):\n",
    "        n_horizontal_edges_per_y = (\n",
    "            self.x_dimension - (self.x_dimension <= 2 or not self.periodic))\n",
    "        for x in range(n_horizontal_edges_per_y):\n",
    "            for y in range(self.y_dimension):\n",
    "                i = self.to_site_index((x, y))\n",
    "                j = self.to_site_index(((x + 1) % self.x_dimension, y))\n",
    "                yield (i, j)\n",
    "                if ordered:\n",
    "                    yield (j, i)\n",
    "\n",
    "    # Function OpenFermion uses for 'vertical_neighbor' edge_type\n",
    "    def vertical_neighbors_iter(self, ordered=True):\n",
    "        n_vertical_edges_per_x = (self.y_dimension -\n",
    "                                  (self.y_dimension <= 2 or not self.periodic))\n",
    "        for y in range(n_vertical_edges_per_x):\n",
    "            for x in range(self.x_dimension):\n",
    "                i = self.to_site_index((x, y))\n",
    "                j = self.to_site_index((x, (y + 1) % self.y_dimension))\n",
    "                yield (i, j)\n",
    "                if ordered:\n",
    "                    yield (j, i)\n",
    "    \n",
    "    # I'm changing this function so that it uses my functions, so I can compare the spectrums, since \n",
    "    # FermiHubbardModel.hamiltonian() will call this to generate the iterable. \n",
    "    def neighbors_iter(self, ordered=True):\n",
    "        return itertools.chain(\n",
    "            #self.horizontal_neighbors_iter(ordered),\n",
    "            #self.vertical_neighbors_iter(ordered)\n",
    "            \n",
    "            # itertools.chain('ABC', 'DEF') = Iterable('ABCDEF') \n",
    "            self.site_pairs_iter('hor_even_neighbor', ordered), \n",
    "            self.site_pairs_iter('hor_odd_neighbor', ordered), \n",
    "            self.site_pairs_iter('ver_even_neighbor', ordered), \n",
    "            self.site_pairs_iter('ver_odd_neighbor', ordered), \n",
    "        )\n",
    "\n",
    "\n",
    "lattice = DecomposedHubbardSquareLattice(x_n, y_n, n_dofs=n_dofs, periodic=periodic, spinless=spinless)\n",
    "hubbard = FermiHubbardModel(lattice , tunneling_parameters=tunneling, interaction_parameters=interaction, \n",
    "                            potential_parameters=potential, magnetic_field=mag_field, \n",
    "                            particle_hole_symmetry=particle_hole_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfermion.ops import FermionOperator\n",
    "\n",
    "def tunneling_operator(i, j, coefficient=1.):\n",
    "    # Copied from hamiltonians/_lattice.py in OpenFermion\n",
    "    return (FermionOperator(((i, 1), (j, 0)), coefficient) + FermionOperator(\n",
    "        ((j, 1), (i, 0)), coefficient.conjugate()))\n",
    "def tunneling_terms_hor_even(hor, even, model):\n",
    "    # Mostly copied from FermiHubbardMode.tunneling_terms() \n",
    "    terms = FermionOperator()\n",
    "    for param in model.tunneling_parameters:\n",
    "        a, aa = param.dofs \n",
    "        # We don't use param.edge_type because it's 'neighbor' and we need to be more specific\n",
    "        if hor and even:\n",
    "            site_pairs = model.lattice.site_pairs_iter('hor_even_neighbor', a != aa)\n",
    "        elif hor and not even: \n",
    "            site_pairs = model.lattice.site_pairs_iter('hor_odd_neighbor', a != aa)\n",
    "        elif not hor and even: \n",
    "            site_pairs = model.lattice.site_pairs_iter('ver_even_neighbor', a != aa)\n",
    "        elif not hor and not even:\n",
    "            site_pairs = model.lattice.site_pairs_iter('ver_odd_neighbor', a != aa)\n",
    "\n",
    "        for r, rr in site_pairs: \n",
    "            for spin_index in model.lattice.spin_indices:\n",
    "                i = model.lattice.to_spin_orbital_index(r, a, spin_index)\n",
    "                j = model.lattice.to_spin_orbital_index(rr, aa, spin_index)\n",
    "                terms += tunneling_operator(i, j, -param.coefficient)\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltonians = {\n",
    "    'hub': hubbard.hamiltonian(), \n",
    "    'non_interacting': hubbard.tunneling_terms(), \n",
    "    'hor_even': tunneling_terms_hor_even(True, True, hubbard), \n",
    "    'hor_odd': tunneling_terms_hor_even(True, False, hubbard), \n",
    "    'ver_even': tunneling_terms_hor_even(False, True, hubbard), \n",
    "    'ver_odd': tunneling_terms_hor_even(False, False, hubbard)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure summing up the parts gives us the whole of non_interacting term \n",
    "print('Sum of horizontal/vertical even/odd terms gives non-interacting term: ', \n",
    "      (hamiltonians['hor_even'] + hamiltonians['hor_odd'] + hamiltonians['ver_even'] + \n",
    "       hamiltonians['ver_odd'] == hamiltonians['non_interacting']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing ground states of tunneling term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall we calculated w_tun and v_tun as the 16 degenerate lowest eigenvalues and eigenvectors of the \n",
    "# tunneling term\n",
    "v_tun.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3412687256771115+0.36542530957053354j)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tun[:,0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "tol = 1e-5\n",
    "def decompose_HF(state):\n",
    "    \"\"\"Decomposes an eigenstate (I can generalize to any state later) as a tensor product of |0> and |1> \"\"\"\n",
    "    tot = 0\n",
    "    for i in range(len(state)):\n",
    "        if np.abs(state[i]) > tol:\n",
    "            tot += 1\n",
    "    return tot\n",
    "        \n",
    "\n",
    "\n",
    "# Why do they all have 196 nonzero coefficients?\n",
    "for j in range(16):\n",
    "    print(decompose_HF(v_tun[:,j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, right, I guess the ground state *doesn't have to be* a pure state in the computational basis. It has to first and foremost be an eigenvector. For the Hadamard matrix, the eigenvectors are $\\ket{+}$ and $\\ket{-}$, where $\\ket{-}$ is the ground state, for example. \n",
    "\n",
    "Okay, so I need to move this to a basis where the Hamiltonian is diagonal. That's just the Bogoliubov transform. Then each eigenvector should be a separate basis state. Before I do that, let's just verify that the 16 degenerate eigenvectors are orthogonal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Inner product was (6.566950927278408e-05+0j) for vectors 0 and 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-80bcf680632c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Inner product was {} for vectors {} and {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcheck_orthogonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_tun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-80bcf680632c>\u001b[0m in \u001b[0;36mcheck_orthogonal\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mvec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfidelity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Inner product was {} for vectors {} and {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcheck_orthogonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_tun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Inner product was (6.566950927278408e-05+0j) for vectors 0 and 1."
     ]
    }
   ],
   "source": [
    "def check_orthogonal(m):\n",
    "    \"\"\"Checks that each vector m[:,i] is orthogonal to the other vectors in m\"\"\"\n",
    "    for i in range(m.shape[1]):\n",
    "        vec1 = m[:,i]\n",
    "        for j in range(i+1, m.shape[1]):\n",
    "            vec2 = m[:,j]\n",
    "            overlap = fidelity(vec1, vec2)\n",
    "            assert np.abs(overlap) < tol, \"Inner product was {} for vectors {} and {}.\".format(overlap, i, j)\n",
    "            \n",
    "check_orthogonal(v_tun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, the eigenvectors of a Hermitian matrix are orthogonal if the eigenvalues are distinct. All these vectors have the same eigenvalues, so the eigenvectors don't have to be orthogonal. \n",
    "\n",
    "Well, we could make them orthogonal with Gram-Schmidt, but wouldn't that change the eigenvalues? No, consider\n",
    "$$ H ( \\ket{\\psi_0} + \\ket{\\psi_1} ) = E_1 \\ket{\\psi_0} + ? \\ket{\\psi_1} $$\n",
    "where $\\ket{\\psi_0}$ is the first eigenvector, and we decomposed the second eigenvector as $\\ket{\\psi_0} + \\ket{\\psi_1}$. Then, by definition of eigenvector, the eigenvalue of $\\ket{\\psi_1}$ must be $E_1$. So, Gram-Schmidt preserves eigenvalues. \n",
    "\n",
    "Simple enough, I'll do GS on the degenerate ground states. Fine, but then what? After the Bogoliubov transform, the eigenvectors no longer represent distinct pure states in HF space. So how can I analyze this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hubbard ground state is a superposition of 16 HF states\n",
    "decompose_HF(v_hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2 x 1 lattice, `v_hub` is a superposition of 4 states, and for a 2 x 2 lattice, `v_hub` is a superposition for 16 states. I'm guessing it's a function $2^{\\mathrm{\\# sites}}$, but why? \n",
    "\n",
    "Hypothesis 1: up and down spins are symmetric here since we don't really have different behavior for them. So, suppose the ground state is defined for $x$ fermions where $x = N / 2$, ie half-filling. The $2^x$ occurs because we can choose to put each fermion in either UP spin or DOWN spin, without changing the energy of the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
