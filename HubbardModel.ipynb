{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hubbard Model\n",
    "\n",
    "I'm planning on running VQE and Trotter simulation on a Hubbard Hamiltonian to better understand its structure. \n",
    "\n",
    "The Hubbard model is a simplification of the interactions of electrons in a solid. It can be used to explain how these interactions yield insulating, magnetic, and superconducting effects (though I don't understand any of this yet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg \n",
    "import scipy.optimize \n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining creation and annihilation operators \n",
    "\n",
    "Since we're describing electrons, the Hubbard Hamiltonian's creation and annihilation operators have the normal fermionic anticommutation relations, namely that for a fermion on site $j,k$ with spin $\\sigma, \\pi$, \n",
    "\n",
    "$$ \\large \\{ c_{j \\sigma}, c^\\dagger_{k \\pi } \\} = \\delta_{jk} \\delta_{\\sigma \\pi} \\qquad \\{ c^\\dagger_{j\\sigma}, c^\\dagger_{k \\pi} \\}= \\{ c_{j\\sigma} c_{k\\pi} \\} = 0  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator: \n",
    "    def __init__(self, _type, spin, qubit, dim):\n",
    "        self.type = _type \n",
    "        self.spin = spin\n",
    "        self.qubit = qubit\n",
    "        self.dim = dim\n",
    "    \n",
    "#     def __mul__(self, b): \n",
    "#         return 0\n",
    "        \n",
    "class CreationOperator(Operator):\n",
    "    def __init__(self, spin, qubit, dim):\n",
    "        super(CreationOperator, self).__init__('creation', spin, qubit, dim)\n",
    "\n",
    "class AnnihilationOperator(Operator):\n",
    "    def __init__(self, spin, qubit, dim):\n",
    "        super(AnnihilationOperator, self).__init__('annihilation', spin, qubit, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1 = CreationOperator('down', 0, 5)\n",
    "a_1 = AnnihilationOperator('up', 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jordan-Wigner Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_JW(operator):\n",
    "    if not issubclass(type(operator), Operator):\n",
    "        raise TypeError(\"operator must be an Operator\")\n",
    "        \n",
    "    result = np.array([[1.0]], dtype='complex128') \n",
    "    string_repr = ''\n",
    "    # Notice the order of the tensor product: gate on 0th qubit is \"leftmost\" in product\n",
    "    for i in range(operator.dim): \n",
    "        if i < operator.qubit: \n",
    "            result = NKron(result, Z)\n",
    "            string_repr = string_repr + 'Z'\n",
    "        elif i == operator.qubit and operator.type == 'creation': \n",
    "            result = NKron(result, (X -1j*Y) / 2)\n",
    "            string_repr = string_repr + '-'\n",
    "        elif i == operator.qubit and operator.type == 'annihilation': \n",
    "            result = NKron(result, (X +1j*Y) / 2) \n",
    "            string_repr = string_repr + '+'\n",
    "        elif i > operator.qubit: \n",
    "            result = NKron(result, I) \n",
    "            string_repr = string_repr + 'I'\n",
    "        else: \n",
    "            raise ValueError(\"Something is wrong with this code!\")\n",
    "    #print(string_repr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encode_JW(c_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Hubbard Hamiltonian\n",
    "\n",
    "Okay, now that we have those preliminaries out of the way, what is the Hubbard Hamiltonian? What's the motivation behind it? How is it useful? \n",
    "\n",
    "Answer these. \n",
    "\n",
    "The Hubbard Hamiltonian: \n",
    "$$ \\large H = -t \\sum_{<j, k>, \\sigma} \\Big( c^\\dagger_{j\\sigma} c_{k\\sigma} + c^\\dagger_{k \\sigma} c_{j \\sigma} \\Big) + U \\sum_j n_{j \\uparrow} n_{j \\downarrow} - \\mu \\sum_j \\Big(n_{j\\uparrow} + n_{j\\downarrow} \\Big) $$\n",
    "\n",
    "The first term is kinetic energy, a fermion moving from one site to another. The symbol $<j, k>$ implies iterating over sites that are adjacent. \n",
    "\n",
    "The second term is interaction energy, additional energy for a doubly-occupied site. \n",
    "\n",
    "The third term is chemical potential, which controls the filling. **Hm, a lot of places don't have this third term (Wikipedia even). Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Hubbard Hamiltonian on a Square Lattice \n",
    "\n",
    "Here is a model of a 2D Hubbard Hamiltontian on a square lattice from [1811.04476](https://arxiv.org/pdf/1811.04476.pdf). We'll represent it by a 2D array: 2D to get the square structure, and in each square `[i][j]`, a dictionary of 4 elements: 'c-up', 'c-down', 'a-up', and 'a-down'. \n",
    "\n",
    "![](2d_hubbard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure N <= 10 or computer explodes!!!!!\n",
    "N_X = 2\n",
    "N_Y = 2\n",
    "N = N_X * N_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use this to make iterating over neighbors easier \n",
    "# NOTE: in HubbardHamiltonian2D, we generate the JW transformation instead of the operator class\n",
    "square_lattice = [[ {'i': i, 'j': j, \n",
    "                     'c-up': CreationOperator('UP', N_Y * i + j, N), \n",
    "                     'c-down': CreationOperator('DOWN', N_Y * i + j, N), \n",
    "                     'a-up': AnnihilationOperator('UP', N_Y * i + j, N), \n",
    "                     'a-down': AnnihilationOperator('DOWN', N_Y * i + j, N)\n",
    "                    } for j in range(N_X)] for i in range(N_Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 0,\n",
       " 'j': 1,\n",
       " 'c-up': <__main__.CreationOperator at 0x7f41dc070e80>,\n",
       " 'c-down': <__main__.CreationOperator at 0x7f41dc070ef0>,\n",
       " 'a-up': <__main__.AnnihilationOperator at 0x7f41dc070f28>,\n",
       " 'a-down': <__main__.AnnihilationOperator at 0x7f41dc070f60>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_lattice[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubbardHamiltonian2D: \n",
    "    def __init__(self, t, U, mu, N_X, N_Y):\n",
    "        self.t = t \n",
    "        self.U = U \n",
    "        self.mu = mu \n",
    "        self.N_X = N_X \n",
    "        self.N_Y = N_Y\n",
    "        self.N = N_X * N_Y \n",
    "        self.square_lattice = self._gen_square_lattice()\n",
    "        self.ham_sets = [self._gen_hor_even_sum(), self._gen_hor_odd_sum(), \n",
    "                         self._gen_ver_even_sum(), self._gen_ver_odd_sum(), \n",
    "                         self._gen_interaction_energy()]\n",
    "        self.hamiltonian = self._gen_hamiltonian()\n",
    "        \n",
    "    def _gen_square_lattice(self):\n",
    "        # We use this to make iterating over neighbors easier \n",
    "        return [[ {'i': i, 'j': j, \n",
    "                   'c-up': encode_JW(CreationOperator('UP', self.N_Y * i + j, self.N)), \n",
    "                   'c-down': encode_JW(CreationOperator('DOWN', self.N_Y * i + j, self.N)), \n",
    "                   'a-up': encode_JW(AnnihilationOperator('UP', self.N_Y * i + j, self.N)), \n",
    "                   'a-down': encode_JW(AnnihilationOperator('DOWN', self.N_Y * i + j, self.N))\n",
    "                  } for j in range(self.N_X)] for i in range(self.N_Y)]\n",
    "    \n",
    "    def _gen_hamiltonian(self): \n",
    "        return (-self.t * (self.ham_sets[0] + self.ham_sets[1] + \n",
    "                           self.ham_sets[2] + self.ham_sets[3]) + \n",
    "                self.U * self.ham_sets[4])\n",
    "    \n",
    "    # I'm calculating the Hamiltonian like this because we'll be separating these terms later for the ansatz\n",
    "    def _gen_hor_even_sum(self): \n",
    "        total = np.eye(2**self.N, dtype='complex128')\n",
    "        for i in range(self.N_Y): \n",
    "            for j in range(self.N_X): \n",
    "                if j % 2 == 0 and j + 1 < self.N_X: \n",
    "                    site = self.square_lattice[i][j]\n",
    "                    next_site = self.square_lattice[i][j+1]\n",
    "                    total += NDot(site['c-up'], next_site['a-up'])\n",
    "                    total += NDot(site['c-down'], next_site['a-down'])\n",
    "                    total += NDot(next_site['c-up'], site['a-up'])\n",
    "                    total += NDot(next_site['c-down'], site['a-down'])\n",
    "        return total \n",
    "    \n",
    "    def _gen_hor_odd_sum(self): \n",
    "        total = np.eye(2**self.N, dtype='complex128')\n",
    "        for i in range(self.N_Y): \n",
    "            for j in range(self.N_X): \n",
    "                if j % 2 == 1 and j + 1 < self.N_X: \n",
    "                    site = self.square_lattice[i][j]\n",
    "                    next_site = self.square_lattice[i][j+1]\n",
    "                    total += NDot(site['c-up'], next_site['a-up'])\n",
    "                    total += NDot(site['c-down'], next_site['a-down'])\n",
    "                    total += NDot(next_site['c-up'], site['a-up'])\n",
    "                    total += NDot(next_site['c-down'], site['a-down'])\n",
    "        return total \n",
    "    \n",
    "    def _gen_ver_even_sum(self):\n",
    "        total = np.eye(2**self.N, dtype='complex128')\n",
    "        for i in range(self.N_Y): \n",
    "            if i % 2 == 0 and i + 1 < self.N_Y: \n",
    "                for j in range(self.N_X): \n",
    "                    site = self.square_lattice[i][j]\n",
    "                    next_site = self.square_lattice[i+1][j]\n",
    "                    total += NDot(site['c-up'], next_site['a-up'])\n",
    "                    total += NDot(site['c-down'], next_site['a-down'])\n",
    "                    total += NDot(next_site['c-up'], site['a-up'])\n",
    "                    total += NDot(next_site['c-down'], site['a-down'])\n",
    "        return total \n",
    "    \n",
    "    def _gen_ver_odd_sum(self): \n",
    "        total = np.eye(2**self.N, dtype='complex128')\n",
    "        for i in range(self.N_Y): \n",
    "            if i % 2 == 1 and i + 1 < self.N_Y: \n",
    "                for j in range(self.N_X): \n",
    "                    site = self.square_lattice[i][j]\n",
    "                    next_site = self.square_lattice[i+1][j]\n",
    "                    total += NDot(site['c-up'], next_site['a-up'])\n",
    "                    total += NDot(site['c-down'], next_site['a-down'])\n",
    "                    total += NDot(next_site['c-up'], site['a-up'])\n",
    "                    total += NDot(next_site['c-down'], site['a-down'])\n",
    "        return total \n",
    "    \n",
    "    def _gen_interaction_energy(self):\n",
    "        total = np.eye(2**self.N, dtype='complex128')\n",
    "        for i in range(self.N_Y): \n",
    "            for j in range(self.N_X): \n",
    "                site = self.square_lattice[i][j] \n",
    "                total += NDot(site['c-up'], site['a-up'], site['c-down'], site['a-down'])\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = HubbardHamiltonian2D(1, 2, 0, N_X, N_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground state energy:  -4.0\n",
      "Ground state:  [[ 0. +0.j]\n",
      " [-0.5+0.j]\n",
      " [-0.5+0.j]\n",
      " [ 0. +0.j]\n",
      " [-0.5+0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]\n",
      " [-0.5+0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]\n",
      " [ 0. +0.j]]\n",
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "eig = np.linalg.eigh(x.hamiltonian)\n",
    "index = np.argmin(eig[0])\n",
    "print('Ground state energy: ', eig[0][index])\n",
    "gstate = np.transpose(NKron(eig[1][:,index]))\n",
    "gstate = gstate / np.linalg.norm(gstate)\n",
    "print('Ground state: ', gstate)\n",
    "print(gstate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.+0.j]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.transpose(np.conj(gstate)), np.dot(x.hamiltonian, gstate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Hamiltonian Ansatz\n",
    "\n",
    "The VHA is an ansatz deeply connected to time-evolution of the system. It splits the Hamiltonian into sub-operators and then does time-evolution for those operators: \n",
    "$$\\large U(\\theta) = \\prod_{k=1}^n \\prod_{\\alpha=1}^N \\exp \\Big( i\\theta_{\\alpha, k} H_{\\alpha} \\Big) $$\n",
    "where $H_\\alpha$ are the sub-Hamiltonians and $\\theta$ are the parameters being optimized. \n",
    "\n",
    "**Question:** Is product from $k=1$ to $n$ meant to indicate multiple iterations of the algorithm? So are there only $N$ parameters, or are there $n \\cdot N$? I think it's the former, because $\\Big( \\exp (i \\theta_{1 k} H_1) \\cdots \\exp (i \\theta_{N k} H_N) \\Big)$ commutes with itself, so we can combine terms.  \n",
    "\n",
    "**Question:** Why is this a good ansatz? It seems it only has access to states that are evolutions of the state we start with. Why is that a guarantee that it'll approximate the ground state? \n",
    "\n",
    "In [1811.04476](https://arxiv.org/pdf/1811.04476.pdf) they use $N=5$, splitting it as I did above: even and odd horizontal hopping terms, even and odd vertical horizontal terms, and the on-site interaction terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_evo(ham, t): \n",
    "    # returns e^{i*t*ham}\n",
    "    # scipy.linalg.expm() uses the Pade approximant; try to understand more of how it works because it seems \n",
    "    # pretty useful: https://en.wikipedia.org/wiki/Pad%C3%A9_approximant\n",
    "    return scipy.linalg.expm(1j * t * ham)\n",
    "\n",
    "def prod_time_evo(ham_sets, ts):\n",
    "    result = 1 \n",
    "    for pair in zip(ham_sets, ts): \n",
    "        result *= time_evo(pair[0], pair[1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VHA: \n",
    "    def __init__(self, hubbard, start_state): \n",
    "        self.ham_sets = hubbard.ham_sets \n",
    "        self.hamiltonian = hubbard.hamiltonian\n",
    "        self.energies = []\n",
    "        self.start_state = start_state\n",
    "        self.start_params = np.array([.5 for i in range(5)])\n",
    "            \n",
    "    def optimize(self):  \n",
    "        self.energies = []\n",
    "        \n",
    "        def energy(t_params): \n",
    "            unitary = prod_time_evo(self.ham_sets, np.real(t_params))\n",
    "            state = np.dot(unitary, self.start_state)\n",
    "            curr_energy = np.dot(np.transpose(np.conj(state)), np.dot(self.hamiltonian, state))[0][0]\n",
    "            #print(curr_energy)\n",
    "            self.energies.append(curr_energy)\n",
    "            return curr_energy\n",
    "                    \n",
    "        self.sol = scipy.optimize.minimize(energy, self.start_params, method='L-BFGS-B', \n",
    "                                           bounds=[(0, 3) for i in range(len(self.start_params))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vha = VHA(x, gstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warren/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py:705: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  grad[k] = df\n",
      "/home/warren/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:338: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  isave, dsave, maxls)\n"
     ]
    }
   ],
   "source": [
    "vha.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum energy:  (-4.000000000000002+0j)\n",
      "Number of iterations:  12\n",
      "Estimated ground state:  [[0.        +0.j        ]\n",
      " [0.20807342-0.45464871j]\n",
      " [0.20807342-0.45464871j]\n",
      " [0.        +0.j        ]\n",
      " [0.20807342-0.45464871j]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]\n",
      " [0.20807342-0.45464871j]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]\n",
      " [0.        +0.j        ]]\n",
      "[0.  0.5 0.  0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print('Minimum energy: ', vha.sol.fun)\n",
    "print('Number of iterations: ', vha.sol.nfev)\n",
    "print('Estimated ground state: ', np.dot(prod_time_evo(vha.ham_sets, vha.sol.x), vha.start_state))\n",
    "print(vha.sol.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Ground State of Non-interacting Terms\n",
    "\n",
    "VHA works because finding the ground state of non-interacting terms is efficiently computable on a QC and the VHA can evolve from that ground state to the ground state of the entire Hubbard Hamiltonian. \n",
    "\n",
    "We'll start by finding the ground state by using numpy to see if this actually work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_interacting_ham = 0\n",
    "for i in range(4): \n",
    "    non_interacting_ham += x.ham_sets[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest energy:  -1.5092094240998222e-15\n",
      "(16, 1)\n",
      "(16, 16)\n"
     ]
    }
   ],
   "source": [
    "eig_non = np.linalg.eigh(non_interacting_ham)\n",
    "genergy_non = eig_non[0][0]\n",
    "print('Lowest energy: ', genergy_non)\n",
    "gstate_non = np.transpose(NKron(eig_non[1][:,0]))\n",
    "print(gstate_non.shape)\n",
    "print(non_interacting_ham.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.50920942e-15, -1.39925744e-15,  1.01195168e-15,  3.00480632e-15,\n",
       "        4.00000000e+00,  4.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n",
       "        4.00000000e+00,  4.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n",
       "        8.00000000e+00,  8.00000000e+00,  8.00000000e+00,  8.00000000e+00])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_non[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00+0.j],\n",
       "       [ 0.00000000e+00+0.j],\n",
       "       [ 2.92374430e-17+0.j],\n",
       "       [-7.88494788e-03+0.j],\n",
       "       [-2.92374430e-17+0.j],\n",
       "       [-3.16613301e-01+0.j],\n",
       "       [ 8.21029378e-17+0.j],\n",
       "       [ 4.84878409e-01+0.j],\n",
       "       [ 0.00000000e+00+0.j],\n",
       "       [ 8.44305159e-17+0.j],\n",
       "       [ 3.16613301e-01+0.j],\n",
       "       [ 4.05692955e-01+0.j],\n",
       "       [ 7.88494788e-03+0.j],\n",
       "       [ 4.05692955e-01+0.j],\n",
       "       [ 4.84878409e-01+0.j],\n",
       "       [ 0.00000000e+00+0.j]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.transpose(NKron(eig_non[1][:,4]))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00+0.j],\n",
       "       [-1.23259516e-32+0.j],\n",
       "       [ 1.16949772e-16+0.j],\n",
       "       [-3.15397915e-02+0.j],\n",
       "       [-1.16949772e-16+0.j],\n",
       "       [-1.26645320e+00+0.j],\n",
       "       [ 1.11022302e-16+0.j],\n",
       "       [ 1.93951364e+00+0.j],\n",
       "       [-1.23259516e-32+0.j],\n",
       "       [-3.33066907e-16+0.j],\n",
       "       [ 1.26645320e+00+0.j],\n",
       "       [ 1.62277182e+00+0.j],\n",
       "       [ 3.15397915e-02+0.j],\n",
       "       [ 1.62277182e+00+0.j],\n",
       "       [ 1.93951364e+00+0.j],\n",
       "       [ 0.00000000e+00+0.j]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prod = np.dot(non_interacting_ham, test)\n",
    "test_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9237443e-17]\n",
      "[1.16949772e-16]\n",
      "[3.41931228e-33]\n",
      "---\n",
      "[-0.00788495]\n",
      "[-0.03153979]\n",
      "[0.00024869]\n",
      "---\n",
      "[-2.9237443e-17]\n",
      "[-1.16949772e-16]\n",
      "[0.00024869]\n",
      "---\n",
      "[-0.3166133]\n",
      "[-1.2664532]\n",
      "[0.40122462]\n",
      "---\n",
      "[8.21029378e-17]\n",
      "[1.11022302e-16]\n",
      "[0.40122462]\n",
      "---\n",
      "[0.48487841]\n",
      "[1.93951364]\n",
      "[1.34165291]\n",
      "---\n",
      "[8.44305159e-17]\n",
      "[-3.33066907e-16]\n",
      "[1.34165291]\n",
      "---\n",
      "[0.3166133]\n",
      "[1.2664532]\n",
      "[1.74262883]\n",
      "---\n",
      "[0.40569295]\n",
      "[1.62277182]\n",
      "[2.40097593]\n",
      "---\n",
      "[0.00788495]\n",
      "[0.03153979]\n",
      "[2.40122462]\n",
      "---\n",
      "[0.40569295]\n",
      "[1.62277182]\n",
      "[3.05957171]\n",
      "---\n",
      "[0.48487841]\n",
      "[1.93951364]\n",
      "[4.]\n",
      "---\n",
      "Where does the e-31 come from?!?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.conjugate(np.transpose(test)), test)\n",
    "conj = np.conjugate(test)\n",
    "res = 0\n",
    "for i in range(len(test)):\n",
    "    con = np.real(conj[i])\n",
    "    pro = np.real(test_prod[i])\n",
    "    if np.abs(con) < 1e-20: \n",
    "        continue\n",
    "    elif np.abs(pro) < 1e-20: \n",
    "        continue\n",
    "    else: \n",
    "        res += con * pro\n",
    "    print(con)\n",
    "    print(pro)\n",
    "    print(res)\n",
    "    print('---') \n",
    "print('Where does the e-31 come from?!?')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.041481514324134e-15\n",
      "(16, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.9721522630525295e-31+0j)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = np.dot(non_interacting_ham, gstate_non)\n",
    "print(np.linalg.norm(times))\n",
    "print(times.shape)\n",
    "np.dot(np.conjugate(np.transpose(gstate_non)), times)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4804535845748784e-08+0j)\n",
      "(1.0104793985170492e-09+5.169878828456423e-26j)\n",
      "(1.6169386539454745e-08+8.271806125530277e-25j)\n",
      "(4.567021038063102e-31-7.7037197775487245e-34j)\n",
      "(-2.0000000000000004+0j)\n",
      "(1.295187887600416e-32+0j)\n",
      "(6+2.220446049250313e-16j)\n",
      "(1.2748508911172723e-08+0j)\n"
     ]
    }
   ],
   "source": [
    "for ind in range(4, 12): \n",
    "    vha = VHA(x, np.transpose(NKron(eig_non[1][:,ind])))\n",
    "    vha.optimize()\n",
    "    print(vha.sol.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
